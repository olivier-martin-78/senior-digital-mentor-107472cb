
import { useState, useRef, useCallback, useEffect } from 'react';
import { toast } from '@/hooks/use-toast';

interface AdaptiveAudioRecorderHook {
  isRecording: boolean;
  audioBlob: Blob | null;
  audioUrl: string | null;
  startRecording: () => Promise<void>;
  stopRecording: () => Promise<void>;
  clearRecording: () => void;
  recordingTime: number;
  recordingFormat: string;
}

// D√©tecter la plateforme et choisir le format optimal
const getOptimalAudioFormat = (): { mimeType: string; extension: string } => {
  const isIPad = /iPad/.test(navigator.userAgent) || 
                (navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1);
  const isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent);
  
  // Sur iPad ou Safari, privil√©gier MP3 pour la compatibilit√©
  if (isIPad || isSafari) {
    // Tester la disponibilit√© des formats
    if (MediaRecorder.isTypeSupported('audio/mp4')) {
      return { mimeType: 'audio/mp4', extension: 'mp4' };
    }
    if (MediaRecorder.isTypeSupported('audio/mpeg')) {
      return { mimeType: 'audio/mpeg', extension: 'mp3' };
    }
  }
  
  // Pour les autres plateformes, utiliser WebM (meilleure qualit√©/compression)
  if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) {
    return { mimeType: 'audio/webm;codecs=opus', extension: 'webm' };
  }
  if (MediaRecorder.isTypeSupported('audio/webm')) {
    return { mimeType: 'audio/webm', extension: 'webm' };
  }
  
  // Fallback ultime
  return { mimeType: '', extension: 'webm' };
};

export const useAdaptiveVoiceRecorder = (): AdaptiveAudioRecorderHook => {
  const [isRecording, setIsRecording] = useState<boolean>(false);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const [audioUrl, setAudioUrl] = useState<string | null>(null);
  const [recordingTime, setRecordingTime] = useState<number>(0);
  const [recordingFormat, setRecordingFormat] = useState<string>('');
  
  const mediaRecorder = useRef<MediaRecorder | null>(null);
  const audioChunks = useRef<Blob[]>([]);
  const streamRef = useRef<MediaStream | null>(null);
  const timerRef = useRef<NodeJS.Timeout | null>(null);
  const isProcessingRef = useRef<boolean>(false);
  const isInitializingRef = useRef<boolean>(false);
  
  console.log('üé§ useAdaptiveVoiceRecorder render - √âtat:', {
    isRecording,
    hasBlob: !!audioBlob,
    hasUrl: !!audioUrl,
    recordingFormat,
    isProcessing: isProcessingRef.current,
    isInitializing: isInitializingRef.current
  });
  
  // Nettoyer les ressources lors du d√©montage
  useEffect(() => {
    return () => {
      console.log('üßπ useAdaptiveVoiceRecorder - D√©montage du hook d√©tect√©');
      
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
        streamRef.current = null;
      }
      
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
      }
    };
  }, [audioUrl]);
  
  // Gestion du timer d'enregistrement
  useEffect(() => {
    if (isRecording) {
      console.log('‚è±Ô∏è D√©marrage du timer d\'enregistrement');
      timerRef.current = setInterval(() => {
        setRecordingTime(prev => prev + 1);
      }, 1000);
    } else {
      if (timerRef.current) {
        console.log('‚è±Ô∏è Arr√™t du timer d\'enregistrement');
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
      setRecordingTime(0);
    }
    
    return () => {
      if (timerRef.current) {
        clearInterval(timerRef.current);
        timerRef.current = null;
      }
    };
  }, [isRecording]);
  
  const startRecording = useCallback(async () => {
    console.log('üéôÔ∏è === D√âBUT PROCESSUS D\'ENREGISTREMENT ADAPTATIF ===');
    
    if (isInitializingRef.current || isRecording) {
      console.log('‚ö†Ô∏è Enregistrement d√©j√† en cours');
      return;
    }
    
    isInitializingRef.current = true;
    
    try {
      console.log("üé§ Demande d'autorisation pour le microphone...");
      const stream = await navigator.mediaDevices.getUserMedia({ 
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100
        }
      });
      streamRef.current = stream;
      
      console.log("‚úÖ Autorisation accord√©e, d√©tection du format optimal...");
      
      // D√©tecter le format optimal pour cette plateforme
      const optimalFormat = getOptimalAudioFormat();
      console.log('üéµ Format optimal d√©tect√©:', optimalFormat);
      setRecordingFormat(optimalFormat.extension);
      
      // Nettoyer les anciennes donn√©es
      setAudioBlob(null);
      if (audioUrl) {
        URL.revokeObjectURL(audioUrl);
        setAudioUrl(null);
      }
      audioChunks.current = [];
      setRecordingTime(0);
      isProcessingRef.current = false;
      
      // Cr√©er le MediaRecorder avec le format optimal
      const recorderOptions: MediaRecorderOptions = {
        bitsPerSecond: 128000
      };
      
      if (optimalFormat.mimeType) {
        recorderOptions.mimeType = optimalFormat.mimeType;
      }
      
      console.log('üéµ Configuration MediaRecorder:', recorderOptions);
      
      const recorder = new MediaRecorder(stream, recorderOptions);
      mediaRecorder.current = recorder;
      
      recorder.ondataavailable = (event) => {
        console.log('üìä Donn√©es audio re√ßues:', event.data.size, 'octets, format:', optimalFormat.extension);
        if (event.data.size > 0) {
          audioChunks.current.push(event.data);
          console.log('üì¶ Total chunks collect√©s:', audioChunks.current.length);
        }
      };
      
      recorder.onstop = () => {
        console.log('üõë === √âV√âNEMENT STOP D√âCLENCH√â ===');
        console.log('üõë Enregistrement arr√™t√©, chunks collect√©s:', audioChunks.current.length);
        
        if (isProcessingRef.current) {
          console.log('‚ö†Ô∏è Traitement d√©j√† en cours, √©viter le doublon');
          return;
        }
        isProcessingRef.current = true;
        
        setTimeout(() => {
          console.log('üìä Chunks finaux disponibles:', audioChunks.current.length);
          
          if (audioChunks.current.length > 0) {
            const totalSize = audioChunks.current.reduce((total, chunk) => total + chunk.size, 0);
            console.log('üìä Taille totale des chunks:', totalSize, 'octets');
            
            if (totalSize > 0) {
              const blob = new Blob(audioChunks.current, { 
                type: optimalFormat.mimeType || `audio/${optimalFormat.extension}` 
              });
              const url = URL.createObjectURL(blob);
              
              console.log("‚úÖ Blob audio cr√©√©:", {
                size: blob.size,
                type: blob.type,
                format: optimalFormat.extension
              });
              
              setAudioBlob(blob);
              setAudioUrl(url);
            } else {
              console.warn("‚ö†Ô∏è Chunks vides d√©tect√©s");
              toast({
                title: "Enregistrement trop court",
                description: "Veuillez enregistrer pendant au moins 2 secondes.",
                variant: "destructive",
              });
            }
          } else {
            console.warn("‚ö†Ô∏è Aucune donn√©e audio collect√©e");
            toast({
              title: "Erreur d'enregistrement",
              description: "Aucune donn√©e audio n'a √©t√© captur√©e. Veuillez r√©essayer en parlant plus fort.",
              variant: "destructive",
            });
          }
          
          setIsRecording(false);
          isInitializingRef.current = false;
          
          if (streamRef.current) {
            streamRef.current.getTracks().forEach(track => track.stop());
            streamRef.current = null;
          }
          
          isProcessingRef.current = false;
        }, 1000);
      };
      
      recorder.onerror = (event) => {
        console.error('‚ùå Erreur MediaRecorder:', event);
        setIsRecording(false);
        isInitializingRef.current = false;
        isProcessingRef.current = false;
        toast({
          title: "Erreur d'enregistrement",
          description: "Une erreur est survenue pendant l'enregistrement.",
          variant: "destructive",
        });
      };
      
      console.log('üé¨ D√©marrage de l\'enregistrement...');
      recorder.start(500);
      setIsRecording(true);
      isInitializingRef.current = false;
      
      console.log('üéôÔ∏è Enregistrement d√©marr√© avec succ√®s, format:', optimalFormat.extension);
      
    } catch (error) {
      console.error("‚ùå Erreur lors de l'acc√®s au microphone:", error);
      setIsRecording(false);
      setRecordingTime(0);
      isInitializingRef.current = false;
      isProcessingRef.current = false;
      
      let errorMessage = "Veuillez v√©rifier que vous avez accord√© les permissions n√©cessaires √† votre navigateur.";
      
      if (error instanceof Error) {
        if (error.name === 'NotAllowedError') {
          errorMessage = "Permission refus√©e. Veuillez autoriser l'acc√®s au microphone.";
        } else if (error.name === 'NotFoundError') {
          errorMessage = "Aucun microphone d√©tect√©. V√©rifiez votre mat√©riel.";
        }
      }
      
      toast({
        title: "Erreur d'acc√®s au microphone",
        description: errorMessage,
        variant: "destructive",
      });
    }
  }, [audioUrl]);
  
  const stopRecording = useCallback(async () => {
    console.log('üõë === DEMANDE D\'ARR√äT MANUEL ===');
    console.log('üîç √âtat MediaRecorder:', mediaRecorder.current?.state);
    console.log('üîç Temps d\'enregistrement:', recordingTime);
    
    if (!mediaRecorder.current || !isRecording) {
      console.log('‚ùå Aucun enregistrement actif √† arr√™ter');
      return;
    }
    
    if (recordingTime < 2) {
      console.log('‚ö†Ô∏è Enregistrement trop court:', recordingTime, 'secondes');
      toast({
        title: "Enregistrement trop court",
        description: "Veuillez enregistrer pendant au moins 2 secondes.",
        variant: "destructive",
      });
      return;
    }
    
    if (mediaRecorder.current.state === 'recording') {
      try {
        console.log("üõë Arr√™t de l'enregistrement en cours...");
        mediaRecorder.current.requestData();
        await new Promise(resolve => setTimeout(resolve, 300));
        console.log('üõë Appel de recorder.stop()');
        mediaRecorder.current.stop();
      } catch (error) {
        console.error("Erreur lors de l'arr√™t de l'enregistrement:", error);
        setIsRecording(false);
        setRecordingTime(0);
        toast({
          title: "Erreur d'enregistrement",
          description: "Un probl√®me est survenu lors de l'arr√™t de l'enregistrement.",
          variant: "destructive",
        });
      }
    }
  }, [isRecording, recordingTime]);
  
  const clearRecording = useCallback(() => {
    console.log('üóëÔ∏è Suppression de l\'enregistrement');
    if (audioUrl) {
      URL.revokeObjectURL(audioUrl);
    }
    
    setAudioBlob(null);
    setAudioUrl(null);
    setRecordingFormat('');
  }, [audioUrl]);
  
  return {
    isRecording,
    audioBlob,
    audioUrl,
    startRecording,
    stopRecording,
    clearRecording,
    recordingTime,
    recordingFormat
  };
};

export default useAdaptiveVoiceRecorder;
